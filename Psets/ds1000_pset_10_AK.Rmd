---
title: "Problem Set 10"
subtitle: "Clustering"
author: "[YOUR NAME]"
institute: "Vanderbilt University"
date: "Due Date: 2024-04-05"
output:
  html_document: default
---

```{r,include=F}
knitr::opts_chunk$set(error=TRUE)
```

Open `RStudio` and create a new RMarkDown file (`.Rmd`) by going to `File -> New File -> R Markdown...`.
Accept defaults and save this file as `[LAST NAME]_ps10.Rmd` to your `code` folder.

Copy and paste the contents of this `.Rmd` file into your `[LAST NAME]_ps10.Rmd` file. Then change the `author: [Your Name]` to your name.

We will be using the `pres_elec.rds` file from the course [github page](https://github.com/jbisbee1/DS1000_S2024/raw/main/data/pres_elec.rds).

All of the following questions should be answered in this `.Rmd` file. There are code chunks with incomplete code that need to be filled in. 

This problem set is worth 8 total points, plus two extra credit points. The point values for each question are indicated in brackets below. To receive full credit, you must have the correct code. In addition, some questions ask you to provide a written response in addition to the code.

You are free to rely on whatever resources you need to complete this problem set, including lecture notes, lecture presentations, Google, your classmates...you name it. However, the final submission must be complete by you. There are no group assignments. To submit, compiled the completed problem set and upload the PDF file to Brightspace on Friday by midnight. Also note that the TAs and professors will not respond to Campuswire posts after 5PM on Friday, so don't wait until the last minute to get started!

**Good luck!**

*Copy the link to ChatGPT you used here: _____________________

## Question 0
Require `tidyverse` and `tidymodels`, and then load the [`pres_elec.rds`](https://github.com/jbisbee1/DS1000_S2024/raw/main/data/pres_elec.rds) data to an object called `dat`.
```{r,warning=F,echo=F,message=F}
require(tidyverse)
require(tidymodels)
dat <- read_rds('https://github.com/jbisbee1/DS1000_S2024/raw/main/data/pres_elec.rds')
```


## Question 1 [2 points]
Describe the data. What is the unit of analysis? What information do the columns provide? What is the period described (i.e., how far back in time does the data go?). Is there any missing data? If so, "where" is it, in terms of both columns and in terms of the observations that have missing data?

```{r}
glimpse(dat)
summary(dat)

dat %>%
  count(year)

dat %>%
  filter(is.na(RepVotes))

dat %>%
  filter(is.na(DemVotes))
```

>- The unit of analysis is a county-by-presidential election. We have information on the state, county, and year, along with counts of the total votes for the Republican, Democrat, and in total; as well as information on the candidates themselves, including their name and their "status". The data covers the period from 1972 to 2020. There are only two missing observations for both the Republican Votes and the Democrat Votes: Bedford City, VA in 2016 and Norfolk County, VA in 2020.

## Question 2 [2 points]
Perform *k*-means analysis on the Republican and Democrat votes with *k* = 2, and then plot the results, coloring the points by cluster assignment. Then predict the `GOP_win` binary outcome as a function of the cluster assignment using a logit regression. Make sure to `factor(cluster)` in the regression. What is the AUC for this model? Finally, use cross validation with an 80-20% split to re-calculate the AUC. Overall, would you say that the *k*-means algorithm helps you predict which counties vote Republican?

```{r}
set.seed(123)
# K-means with k = 2
kRes <- dat %>%
  select(DemVotes,RepVotes) %>%
  drop_na() %>%
  kmeans(centers = 2)

# Plotting the result
dat %>%
  select(DemVotes,RepVotes) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster) %>%
  ggplot(aes(x = RepVotes,y = DemVotes,color = factor(cluster),group = 1)) + 
  geom_point() + 
  labs(x = 'GOP Votes',
       y = 'Democrat Votes',
       color = 'k-means Cluster')

# Create dataset for analysis
toanal <- dat %>%
  select(DemVotes,RepVotes,GOP_win) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster)

# Estimate logit model
summary(m <- glm(GOP_win ~ factor(cluster),toanal,family = binomial))

# Calculate AUC
roc_auc(toanal %>%
          mutate(prob_win = predict(m,type = 'response'),
                 truth = factor(GOP_win,levels = c('1','0'))),
        truth,prob_win)

# Calculate cross-validated result
cvRes <- NULL
for(i in 1:100) {
  inds <- sample(1:nrow(toanal),size = round(nrow(toanal)*.8),replace = F)
  train <- toanal %>% slice(inds)
  test <- toanal %>% slice(-inds)
  
  summary(m <- glm(GOP_win ~ factor(cluster),train,family = binomial))


  cvRes <- cvRes %>%
    bind_rows(roc_auc(test %>%
                        mutate(prob_win = predict(m,newdata = test,type = 'response'),
                               truth = factor(GOP_win,levels = c('1','0'))),
                      truth,prob_win) %>%
                mutate(cvInd = i))
}

# Cross-validated AUC
cvRes %>%
  summarise(auc = mean(.estimate))
```

>- The AUC in either the full data or in the cross validated result is a very low 0.52, meaning that this is a very poor model. This means that the *k*-means clustering algorithm's groups were not helpful in predicting whether a county would elect a Republican or a Democrat.

## Question 3 [2 points]
Now create an elbow plot by looping over potential values of *k* from 1 to 30 and plotting the *k* on the x-axis and the total Within Sum of Squares (total WSS) on the y-axis. What value of *k* would you use? Then re-run the preceding analysis with that value of *k* and interpret the results. Does the model improve?

```{r,warning=F}
# Looking at multiple values of k
kRes <- NULL
for(k in 1:30) {
  # Calculate k-means cluster solution for given value of k
  kResTmp <- dat %>%
  select(DemVotes,RepVotes) %>%
  drop_na() %>%
  kmeans(centers = k)
  
  # Save result including value of k and the total WSS
  kRes <- data.frame(withinSS = kResTmp$tot.withinss,
             k = k) %>%
    bind_rows(kRes)
}

# Plotting the elbow plot. Looks like k=4 is the elbow?
kRes %>%
  ggplot(aes(x = k,y = withinSS)) + 
  geom_line() + 
  geom_point() + 
  scale_x_continuous(breaks = 1:30)

# Rerunning with k = 4
kRes <- dat %>%
  select(DemVotes,RepVotes) %>%
  drop_na() %>%
  kmeans(centers = 4,nstart = 25)

# Plotting again
dat %>%
  select(DemVotes,RepVotes) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster) %>%
  ggplot(aes(x = RepVotes,y = DemVotes,color = factor(cluster),group = 1)) + 
  geom_point() + 
  labs(x = 'GOP Votes',
       y = 'Democrat Votes',
       color = 'k-means Cluster')

# Create dataset for analysis 
toanal <- dat %>%
  select(DemVotes,RepVotes,GOP_win) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster)

# Estimate logit model
summary(m <- glm(GOP_win ~ factor(cluster),toanal,family = binomial))

# Calculate AUC
roc_auc(toanal %>%
          mutate(prob_win = predict(m,type = 'response'),
                 truth = factor(GOP_win,levels = c('1','0'))),
        truth,prob_win)

# Calculate cross-validated result
cvRes <- NULL
for(i in 1:100) {
  inds <- sample(1:nrow(toanal),size = round(nrow(toanal)*.8),replace = F)
  train <- toanal %>% slice(inds)
  test <- toanal %>% slice(-inds)
  
  summary(m <- glm(GOP_win ~ factor(cluster),train,family = binomial))


  cvRes <- cvRes %>%
    bind_rows(roc_auc(test %>%
                        mutate(prob_win = predict(m,newdata = test,type = 'response'),
                               truth = factor(GOP_win,levels = c('1','0'))),
                      truth,prob_win) %>%
                mutate(cvInd = i))
}

# Cross-validated AUC
cvRes %>%
  summarise(auc = mean(.estimate))
```

> - Based on the elbow plot, I would choose a value of 4 because this is where the marginal reductions in within sum of squared errors diminish most clearly. In other words, this is roughly the "elbow" of the plot. However, my model is still terrible at predicting which party wins the presidential election.


## Question 4 [2 points]
Re-do the preceding analysis except instead of using total votes, calculate the percent vote share for Democrats and Republicans in each county. Then identify the optimal value of *k* using the elbow plot visualization, use this as your value of *k* for the clustering solution and again plot the results. Now use a logit regression to predict `GOP_win` as a function of the cluster membership for each county and calculate the AUC using the same cross validation method. Does your answer change?

```{r,warning=F}
# Wrangle data to get DEM and REP vote shares
dat <- dat %>%
  mutate(DemShare = DemVotes / TotalVotes,
         RepShare = RepVotes / TotalVotes)

# Re-calculate elbow plot
kRes <- NULL
for(k in 1:30) {
  kResTmp <- dat %>%
  select(DemShare,RepShare) %>% # Using vote shares instead of total votes
  drop_na() %>%
  kmeans(centers = k)
  
  kRes <- data.frame(withinSS = kResTmp$tot.withinss,
             k = k) %>%
    bind_rows(kRes)
}

# Plotting the elbow plot
kRes %>%
  ggplot(aes(x = k,y = withinSS)) + 
  geom_line() + 
  geom_point() + 
  scale_x_continuous(breaks = 1:30)

# Rerunning with k = 4
kRes <- dat %>%
  select(DemShare,RepShare) %>%
  drop_na() %>%
  kmeans(centers = 4,nstart = 25)

dat %>%
  select(DemShare,RepShare) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster) %>%
  ggplot(aes(x = RepShare,y = DemShare,color = factor(cluster),group = 1)) + 
  geom_point() + 
  labs(x = 'GOP Vote %',
       y = 'Democrat Vote %',
       color = 'k-means Cluster')

toanal <- dat %>%
  select(DemShare,RepShare,GOP_win) %>%
  drop_na() %>%
  mutate(cluster = kRes$cluster)

summary(m <- glm(GOP_win ~ factor(cluster),toanal,family = binomial))

roc_auc(toanal %>%
          mutate(prob_win = predict(m,type = 'response'),
                 truth = factor(GOP_win,levels = c('1','0'))),
        truth,prob_win)

cvRes <- NULL
for(i in 1:100) {
  inds <- sample(1:nrow(toanal),size = round(nrow(toanal)*.8),replace = F)
  train <- toanal %>% slice(inds)
  test <- toanal %>% slice(-inds)
  
  summary(m <- glm(GOP_win ~ factor(cluster),train,family = binomial))


  cvRes <- cvRes %>%
    bind_rows(roc_auc(test %>%
                        mutate(prob_win = predict(m,newdata = test,type = 'response'),
                               truth = factor(GOP_win,levels = c('1','0'))),
                      truth,prob_win) %>%
                mutate(cvInd = i))
}

cvRes %>%
  summarise(auc = mean(.estimate))
```

>- The model's performance improves dramatically up to an AUC of 0.935! This is clearly a much better predictor to use!

## Extra Credit [2 points]
Provide an explanation for why the *k*-means results are so much more helpful when run using vote shares instead of total votes.

>- The total votes measures are bad for predicting who wins the presidency because they divide counties by overall size, not politics. In other words, one cluster is created for larger counties who record more votes for both Democrat and Republican candidates simply because they are more populous, and another cluster is created for smaller counties. While potentially interesting for other analyses, these clusters are not helpful for predicting vote choice because they capture county size, not the political make-up.
